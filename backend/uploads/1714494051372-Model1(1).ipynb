{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TEgDjOlrq5cR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Dataset.csv\")"
      ],
      "metadata": {
        "id": "oyNkMKMcrK82"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)\n",
        "data = pd.get_dummies(data)"
      ],
      "metadata": {
        "id": "jLD_yLBmrOAD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=[\"BMI\"])\n",
        "y = data[\"BMR\"]"
      ],
      "metadata": {
        "id": "K2esQ_f9rhSY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "91p5hPMfrn6m"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "bFbDblbBsNJB"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have train and test data X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        \"n_estimators\": [100, 200, 300],\n",
        "        \"max_depth\": [None, 5, 10],\n",
        "        \"min_samples_split\": [2, 5, 10]\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"n_estimators\": [100, 200, 300],\n",
        "        \"learning_rate\": [0.01, 0.1, 0.5],\n",
        "        \"max_depth\": [3, 5, 7]\n",
        "    }\n",
        "}\n",
        "\n",
        "best_models = {name: GridSearchCV(model, param_grid=params, cv=5, scoring='neg_mean_squared_error').fit(X_train_scaled, y_train).best_estimator_\n",
        "               for name, model, params in zip(models.keys(), models.values(), param_grids.values())}\n",
        "\n",
        "# Calculate RMSE scores for each model\n",
        "rmse_scores = {}\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    rmse_scores[name] = rmse\n",
        "\n",
        "# Find the best model based on the minimum RMSE score\n",
        "best_model_name = min(rmse_scores, key=rmse_scores.get)\n",
        "best_model = best_models[best_model_name]\n",
        "\n",
        "print(\"Best Model:\", best_model_name)\n",
        "print(\"RMSE Score:\", rmse_scores[best_model_name])"
      ],
      "metadata": {
        "id": "FUhXWlAass4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in best_models.items():\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "    rmse_scores = [(-score)**0.5 for score in cv_scores]\n",
        "    print(f\"Cross-Validation RMSE for {name}:\", rmse_scores)"
      ],
      "metadata": {
        "id": "v7qm7KbwtMzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a93dfc4-7b53-4827-8fed-8db8aefb153a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation RMSE for Random Forest: [0.500388893285714, 0.7113973744661957, 0.3298156455297856, 0.644112014495397, 0.31744411380829757]\n",
            "Cross-Validation RMSE for Gradient Boosting: [0.3230512879137702, 0.525854684320972, 0.7552958164273694, 0.41619179573286824, 0.33709587159946985]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"Actual Daily Calorie Limit\")\n",
        "plt.ylabel(\"Predicted Daily Calorie Limit\")\n",
        "plt.title(\"Actual vs. Predicted Daily Calorie Limit\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hogYlVkithOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if best_model_name == \"Random Forest\":\n",
        "    feature_importance = best_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_importance})\n",
        "    importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df)\n",
        "    plt.title(\"Random Forest Feature Importance\")\n",
        "    plt.show()\n",
        "elif best_model_name == \"Gradient Boosting\":\n",
        "    feature_importance = best_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_importance})\n",
        "    importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df)\n",
        "    plt.title(\"Gradient Boosting Feature Importance\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6Ipi9HUytonl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}